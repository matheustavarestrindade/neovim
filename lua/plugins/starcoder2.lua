return {}
-- return {
--     {
--         'huggingface/llm.nvim',
--         config = function()
--             local llm = require('llm')
--             print(
--                 vim.api.nvim_call_function("stdpath", { "data" }) .. "/llm_nvim/bin"
--             )
--             llm.setup({
--                 api_token = nil, -- cf Install paragraph
--
--                 -- Config for the huggingface model
--                 context_window = 16384,                      -- max number of tokens for the context window
--                 model = "deepseek-coder:6.7b",            -- the model ID, behavior depends on backend
--                 backend = "ollama",                          -- backend ID, "huggingface" | "ollama" | "openai" | "tgi"
--                 url = "http://localhost:11434/api/generate", -- the http url of the backend
--                 -- set this if the model supports fill in the middle
--                 fim = {
--                     enabled = true,
--                     prefix = "<fim_prefix>",
--                     middle = "<fim_middle>",
--                     suffix = "<fim_suffix>",
--                 },
--                 tokens_to_clear = { "<|endoftext|>" }, -- tokens to remove from the model's output
--
--                 -- parameters that are added to the request body, values are arbitrary, you can set any field:value pair here it will be passed as is to the backend
--                 request_body = {
--                     options = {
--                         num_predict = 60,
--                         temperature = 0.1,
--                         top_p = 0.7,
--                     },
--                 },
--                 debounce_ms = 150,
--                 accept_keymap = "<C-Tab>",
--                 dismiss_keymap = "<S-Tab>",
--                 tls_skip_verify_insecure = false,
--                 -- llm-ls configuration, cf llm-ls section
--                 lsp = {
--                     bin_path = vim.api.nvim_call_function("stdpath", { "data" }) .. "/llm_nvim/llm-ls.exe",
--                     host = nil,
--                     port = nil,
--                     version = "0.5.2",
--                 },
--                 enable_suggestions_on_startup = true,
--                 enable_suggestions_on_files = "*", -- pattern matching syntax to enable suggestions on specific files, either a string or a list of strings
--             })
--         end
--     },
-- }
--
